---
{"dg-publish":true,"permalink":"/linear-algebra/13-invertible-matrices/13-1-inverse-of-a-square-matrix/","tags":["Type/Definition","Topic/Linear_Algebra","Type/Example"]}
---

Types: *N/A*
Examples: *N/A*
Constructions: *N/A*
Generalizations: *N/A*

Properties: [[Linear Algebra/13 Invertible Matrices/13.4 Properties of Matrix Inverses\|13.4 Properties of Matrix Inverses]]
Sufficiencies: *N/A*
Questions: *N/A*

> [!definition|*] Inverse of a Square Matrix
> 
> Let $A \in \mathbb{R}^{n \times n}$ be a square matrix. We say that $A$ is **invertible** iff there exists a matrix $C \in \mathbb{R}^{n \times n}$ such that
> $$
> A \cdot C = C \cdot A = I_{n}
> $$
> where $I_{n}$ is the $n \times n$ [[Linear Algebra/08 Anatomy of Matrices/8.6 Identity Matrix\|8.6 Identity Matrix]]. 
> - $C = A^{-1}$ is the **inverse** of $A$. 
> - An invertible matrix is called **nonsingular** while a matrix that is not invertible is called **singular**
> - ! Not all square matrices are invertible!

**Remark.** Matrix inverses are the inverse of [[Linear Algebra/11 Matrix-Matrix Multiplication/11 Matrix-Matrix Multiplication\|11 Matrix-Matrix Multiplication]]. Only square matrices can be two-side inverses.
 <span style='float:right;'>$\blacklozenge$</span>

---

> [!example] Inverse of a Square Matrix
> Consider matrices
> 
> $$
> A = \begin{bmatrix}
> 2 & 0 \\
> 0 & 3
> \end{bmatrix}, C = \begin{bmatrix}
> \frac{1}{2} & 0 \\
> 0 & \frac{1}{3}
> \end{bmatrix}
> $$

Notice that $C$ is the inverse of $A$, denoted as $C = A^{-1}$, because
$$
A \cdot C = \begin{bmatrix}
2 & 0 \\
0 & 3
\end{bmatrix} \begin{bmatrix}
\frac{1}{2} & 0 \\
0 & \frac{1}{3}
\end{bmatrix} = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}
$$

---

> [!example] Inverse of Shear Matrix
> Consider the matrices
> 
> $$
> S_{31}(-3) = \begin{bmatrix}
> 1 & 0 & 0 \\
> 0 & 1 & 0 \\
> -3 & 0 & 1
> \end{bmatrix}, C= \begin{bmatrix}
> 1 & 0 & 0 \\
> 0 & 1 & 0 \\
> 3 & 0 & 1
> \end{bmatrix}
> $$

We see that $C = \left( S_{31}(-3) \right)^{-1}$ because 
$$
\begin{align*}
S_{31}(-3) \cdot C &=  \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
-3 & 0 & 1
\end{bmatrix} \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
3 & 0 & 1
\end{bmatrix}\\
&= \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\end{align*}
$$

---

> [!conjecture|*] 
> Note if $D \in \mathbb{R}^{n \times n}$ is diagonal with $d_{ii}\neq 0$ for all $i \in \{ n \}$, then
> 
> $$
> D = \begin{bmatrix}
> d_{11} & 0 & \dots & 0 \\
> 0 & d_{21} & \ddots & \vdots \\
> \vdots & \ddots & \ddots & 0 \\
> 0 & \dots & 0 & d_{nn}
> \end{bmatrix}
> $$
> is invertible with
> 
> $$
> D^{-1} = \begin{bmatrix}
> d_{11}^{-1} & 0 & \dots & 0 \\
> 0 & d_{21}^{-1} & \ddots & \vdots \\
> \vdots & \ddots & \ddots & 0 \\
> 0 & \dots & 0 & d_{nn}
> \end{bmatrix}
> $$

Therefore, 
$$
\begin{align}
\text{nonsingular}  & \iff \text{linearly independent columns and square} \\
 & \iff \text{linearly independent rows and square} \\
 & \iff \text{there is a } C \in \mathbb{R}^{n \times n} \text{ with }A \cdot C = CA=I_{n} \text{ and } G = A^{-1}
\end{align}
$$
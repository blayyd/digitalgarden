---
{"dg-publish":true,"permalink":"/linear-algebra/28-eigenvalue-theory/28-3-how-to-identify-if-2x2-matrix-is-positive-definite/","tags":["Type/Example","Topic/Linear_Algebra"]}
---

Types: *N/A*
Examples: *N/A*
Constructions: *N/A*
Generalizations: *N/A*

Properties: [[Calculus 3/13 Multivariable Optimization/13.2 Saddle Points\|13.2 Saddle Points]], [[Calculus 3/06 Lines and Planes/6.7 Intro to Quadratic Surfaces\|6.7 Intro to Quadratic Surfaces]], [[Calculus 4/Quadric Surfaces\|Quadric Surfaces]]
Sufficiencies: *N/A*
Questions: *N/A*

> [!exm|*] 
> When is a $2 \times 2$ symmetric matrix positive definite?
> 
> Suppose we have a symmetric $2 \times 2$ matrix
> $$
> K = \begin{bmatrix}
> k_{11} & k_{12} \\
> k_{21} & k_{22}
> \end{bmatrix}
> $$
> where $k_{12}=k_{21}$ since $K = K^{T}$.
> 


`\begin{proof}[Solution.]`
In order to answer this question for any general $2 \times 2$ symmetric matrix, let's introduce some simpler notation by setting
$$
K = \begin{bmatrix}
a & b \\
b & c
\end{bmatrix}
$$
for any real-valued scalars $a, b, c \in \mathbb{R}$.
- & Note: $\det(K)=ac-b^{2}$

Recall the definition of a [[Linear Algebra/28 Eigenvalue Theory/28.2 Positive Definite Matrix\|28.2 Positive Definite Matrix]].

<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/linear-algebra/28-eigenvalue-theory/28-2-positive-definite-matrix/#76bc31" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">



> [!definition|*] Positive Definite Matrix
> 
> We say that an $n \times n$ matrix $K$ is **positive definite** iff it satisfies the two conditions:
> 1. Symmetry condition: $K = K^{T}$
> 2. Positivity condition: If $\vec{x} \neq  \vec{0}$, then $\vec{x}^{T} K \vec{x} > 0$
> 
> For short hand, we sometimes write $K > 0$ to imply that $K$ is a symmetric, positive definite matrix.

</div></div>
 

With that definition in mind, we ask ourselves how the values of $a, b, c$ relate to the property that $2 \times 2$ symmetric
$$
K = \begin{bmatrix}
a & b \\
b & c
\end{bmatrix}
$$
is positive definite with $\vec{x}^{T} K \vec{x} > 0$ for any $\vec{x} \neq  \vec{0}$. To explore this, suppose
$$
\vec{x} = \begin{bmatrix}
x_{1} & x_{2}
\end{bmatrix}^{T} \neq  \vec{0}
$$
and consider
$$
\begin{align*}
[\vec{x}^{T}]_{1 \times 2} [K]_{2 \times 2} [\vec{x}]_{2 \times 1} &=  \begin{bmatrix}
x_{1} & x_{2}
\end{bmatrix}_{1 \times 2} \begin{bmatrix}
a & b \\
b & c
\end{bmatrix}_{2 \times 2} \begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}_{2 \times 1}\\
&= \begin{bmatrix}
x_{1} & x_{2}
\end{bmatrix}_{1 \times 2} \begin{bmatrix}
ax_{1} + bx_{2} \\
b x_{1} + cx_{2}
\end{bmatrix}_{ 2 \times 1}\\
&= \begin{bmatrix}
ax_{1}+bx_{2}  & bx_{1}+cx_{2}
\end{bmatrix}_{1 \times 2} \begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}_{2 \times 1}\\
\implies \vec{x}^{T} K \vec{x} &= ax_{1}^{2} + bx_{1}x_{2} + bx_{1}x_{2} + cx_{2}^{2} \\
 &= ax_{1}^{2} + 2bx_{1}x_{2}  + cx_{2}^{2}\\
&= a\underbrace{ \left( x_{1}^{2}+2 \frac{b}{a} x_{1} x_{2} \right) }_{ \text{How can we transform this to perfect square?} }+ cx_{2}^{2}
\end{align*}
$$
Let's focus on the expression inside the parenthesis and remember how to complete the square:
$$
x_{1}^{2} + 2 \frac{b}{a}x_{1}x_{2} + ? = \left( x_{1} + \frac{b}{a}x_{2} \right)^{2}
$$
- ? What do we need to add to the LHS to create a perfect square trinomial so that we can factor this as a perfect square?

Here we note that
$$
\begin{align*}
\left( x_{1} + \frac{b}{a} x_{2} \right)^{2} &= \left( x_{1} + \frac{b}{a} x_{2} \right) \cdot \left( x_{1} + \frac{b}{a} x_{2} \right)\\
&= x_{1} \cdot \left( x_{1} + \frac{b}{a}x_{2} \right) + \frac{b}{a}x_{2} \cdot \left( x_{1} + \frac{b}{a}x_{2} \right)\\
&= x_{1}^{2} + \frac{b}{a}x_{1}x_{2} + \frac{b}{a}x_{2}x_{1} + \frac{b^{2}}{a^{2}}x_{2}^{2}\\
&= \underbrace{ x_{1}2 + 2\frac{b}{a}x_{1}x_{2} }_{ \text{starting term} } + \underbrace{ \frac{b^{2}}{a^{2}} x_{2}^{2} }_{ \text{add for perfect square trinomial} }
\end{align*}
$$
Therefore,
$$
\begin{align*}
\implies x_{1}^{2} + 2 \frac{b}{a} x_{1}x_{2} &= x_{1} ^{2} + 2 \frac{b}{a} x_{1}x_{2} + 0\\
&= x_{1} ^{2} + 2 \frac{b}{a} x_{1}x_{2} + \frac{b^{2}}{a^{2}} x^{2} - \frac{b^{2}}{a^{2}}x_{2}^{2}\\
&= \left( x_{1} + \frac{b}{a} x^{2} \right)^{2} - \frac{b^{2}}{a^{2}} x_{2}^{2}
\end{align*}
$$
Looking back at our original problem, we had
$$
\begin{align*}
\vec{x}^{T} K \vec{x} &= \begin{bmatrix}
x_{1} & x_{2}
\end{bmatrix} \begin{bmatrix}
a & b \\
b & a
\end{bmatrix} \begin{bmatrix}
x_{1} \\
x_{2}
\end{bmatrix}\\
&= a x_{1}^{2} + 2 bx_{1}x_{2} + cx_{2}^{2}\\
&= a\left( \underbrace{ x_{1}^{2}+2 \frac{b}{a}x_{1}x_{2} }_{ \text{transform this to perfect square} } \right) + c x_{2}^{2}\\
&= a\left( x_{1}^{2} + 2 \frac{b}{a}x_{1}x_{2} + \frac{b^{2}}{a^{2}}x_{2}^{2} - \frac{b^{2}}{a^{2}}x_{2}^{2} \right) + cx_{2}^{2}\\
&= a\left( x_{1} + \frac{b}{a}x_{2} \right)^{2} - \frac{b^{2}}{a^{2}} x_{2}^{2} + cx_{2}^{2}\\
&= a\left( x_{1} + \frac{b}{a}x^{2} \right) + \left( \underbrace{ c-\frac{b^{2}}{a^{2}} }_{ \text{find common denom} } \right)x_{2}^{2}\\
&= a\left( x_{1} + \frac{b}{a} x_{2} \right)^{2} + \left( \frac{{ac-b^{2}}}{a} \right) x_{2}^{2}
\end{align*}
$$
- & Note that $\det(K)=ac-b^{2}$.

Notice in this new form, we can say something intelligent about when the matrix $K$ is positive definite based on the entries of 
$$
K = \begin{bmatrix}
a & b \\
b & c
\end{bmatrix}
$$
Specifically, we've just shown that for
$$
K = \begin{bmatrix}
a & b \\
b & c
\end{bmatrix}
$$
we can write
$$
\vec{x}^{T} K \vec{x} = a\left( x_{1} + \frac{b}{a}x^{2} \right)^{2} + \left( \frac{{ac-b^{2}}}{a} \right)x_{2}^{2}
$$
where both terms are perfect squares and will therefore never be negative. Let's introduce some new notation to simplify our problem. Let
$$
\begin{align*}
y_{1} &=  x_{1} + \frac{b}{a}x_{2}\\
\beta &= \frac{{ac-b^{2}}}{a}
\end{align*}
$$
Then, we want to know when is the two variable function
$$
ay_{1}^{2} + \beta x_{2}^{2} > 0
$$
where at least one variable $y_{1}$ or $x_{2}$ is nonzero. Note, though, that this depends on coefficients $a$ and $\beta$ since we know
$$
y_{1}^{2} = \left( x_{1}+\frac{b}{a}x_{2} \right)^{2} \geq 0 \text{ and } x_{2}^{2} \geq 0
$$
Specifically, only when both
$$
a >0 \text{ and } \frac{{ac-b^{2}}}{a}=\beta > 0
$$
can we guarantee positivity of our quadratic expression above. However, recall that we had
$$
\beta = \frac{{ac-b^{2}}}{a} = \frac{\det(K)}{a} = \frac{d}{a}
$$
This scalar has a very special property:
> [!claim] 
> If we know the sign of $a$, then the sign of $(ac-b^{2})=\det(K)=d$ determines the sign of $\beta$.

We can check the sign of $\beta$ using the table below.

|                                                      | $d$ positive (with $d>0$ <br>and $sgn(d)=1$) | $d$ negative (with $d<0$ <br>and $sgn(d)=-1$) |     |
| ---------------------------------------------------- | -------------------------------------------- | --------------------------------------------- | --- |
| $a$ positive (with $a>0$ <br>and $sgn(a)=1$)         | $\beta$ positive                             | $\beta$ negative                              |     |
| $a$ negative (with <br>$a<0$)<br>and $sgn(a)=-1$<br> | $\beta$ negative                             | $\beta$ positive                              |     |
 
But we said that for 
$$
K = \begin{bmatrix}
a & b \\
b & c
\end{bmatrix},
$$
$$
\begin{align*}
\vec{x}^{T}K \vec{x} &= a\left( x_{1}+\frac{b}{a}x_{2} \right)^{2} + \left( \frac{{ac-b^{2}}}{a} \right)x_{2}^{2}\\
&= ay_{1}^{2} + \beta x_{2}^{2}
\end{align*}
$$
was for sure positive if $\vec{x} \neq  \vec{0}$ iff
$$
\begin{align}
 & \iff a>0 \text{ and } \beta > 0 \\
 & \iff a > 0 \text{ and } \frac{{ac-b^{2}}}{a}>0 \\
 & \iff a>0 \text{ and } ac-b^{2} > 0 \\
 & \iff a>0 \text{ and } \det(K) > 0
\end{align}
$$
Then, we have developed a condition to check whether any $2 \times 2$ symmetric matrix in the form
$$
K = \begin{bmatrix}
a & b \\
b & c
\end{bmatrix}
$$
is positive definite based on the values of each entry. Specifically, for $[\vec{x}]_{2 \times 1} \neq  \vec{0}$.

> [!claim] Quick check for positive definiteness of any symmetric $2\times2$ matrix
> 
>  $$
> \vec{x}^{T}K \vec{x} > 0 \iff \begin{cases}
> i.  & a > 0 \text{ AND } \\
> ii.  & \det(K) > 0
> \end{cases}
> $$


 `\end{proof}`

---
**Remark.** We can geometrically determine positive and negative definiteness by analyzing the shape of our [[Calculus 4/Quadric Surfaces\|Quadric Surfaces]].
- Positive definite when surface is an elliptical paraboloid pointing up
- Negative definite when function has a [[Calculus 3/13 Multivariable Optimization/13.2 Saddle Points\|saddle point]] (hyperbolic paraboloid)
<iframe src="https://www.geogebra.org/calculator/kpjctuex?embed" width="800" height="600" allowfullscreen style="border: 1px solid #e4e4e4;border-radius: 4px;" frameborder="0"></iframe>

 <span style='float:right;'>$\blacklozenge$</span>
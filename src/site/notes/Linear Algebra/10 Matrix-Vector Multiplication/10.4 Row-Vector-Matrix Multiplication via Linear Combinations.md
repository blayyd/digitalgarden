---
{"dg-publish":true,"permalink":"/linear-algebra/10-matrix-vector-multiplication/10-4-row-vector-matrix-multiplication-via-linear-combinations/","tags":["Type/Definition","Topic/Linear_Algebra"]}
---

Types: *N/A*
Examples: [[Linear Algebra/10 Matrix-Vector Multiplication/10.4.1 Example of Row Vector Matrix Multiplication via Linear Combinations\|10.4.1 Example of Row Vector Matrix Multiplication via Linear Combinations]]
Constructions: *N/A*
Generalizations: *N/A*

Properties: [[Linear Algebra/10 Matrix-Vector Multiplication/10.7 Properties of Row-Vector-Matrix Multiplication\|10.7 Properties of Row-Vector-Matrix Multiplication]]
Sufficiencies: *N/A*
Questions: *N/A*

> [!definition|*] Row-Vector-Matrix Multiplication via Linear Combinations
> 
> Let matrix $A \in \mathbb{R}^{m \times n}$ and [[Linear Algebra/03 Vector Modeling/3.1 Column Vector\|3.1 Column Vector]] $\vec{x} \in \mathbb{R}^{m \times 1}$. Then, the [[Linear Algebra/06 Span and Linear Independence/6.1 Linear Combination of Vectors\|linear combination]] version of the row-vector-matrix product $\vec{x}^{T} A = \vec{b} \in \mathbb{R}^{ 1 \times n}$ is given by the linear combination
> $$
> \begin{align*}
> \vec{x}^{T}A &= x_{1} \begin{bmatrix}
> a_{11} & a_{12} & \dots & a_{1 n} \\
> \end{bmatrix}\\
> &+ x_{2} \begin{bmatrix}
> a_{21}  & a_{22} & \dots & a_{2 n}
> \end{bmatrix}\\
> & \vdots\\
> &+ x_{m} \begin{bmatrix}
> a_{m 1} & a_{m 2} & \dots & a_{mn}
> \end{bmatrix}\\
> &= \vec{b}
> \end{align*}
> $$
> Using summation and [[Linear Algebra/08 Anatomy of Matrices/8.11 Colon Notation\|8.11 Colon Notation]], we write
> $$
> \vec{x}^{T}A = x_{1} A(1,:) + x_{2}A(2,:) + \dots + x_{m} A(m,:) = \sum_{i=1}^{m} x_{i} A(i,:) = \vec{b}
> $$

**Remark.** When the modeling matrix shows up on the right, we cut the matrix into rows.
$$
\begin{align*}
\underset{ \text{algebraic worker} }{ \vec{x}^{T} } \cdot \underset{ \text{modeling matrix} }{ A } &= \vec{b}\\
[\vec{x}]^{T} _{1 \times m} [A]_{m \times n} &=  [\begin{array}{c|c|c}
x_{1}&x_{2}&\dots&x_{m}
\end{array}]_{1 \times m} \begin{bmatrix}
A(1,:) \\
\hline A(2,:) \\
\hline \vdots \\
\hline A(m,:)
\end{bmatrix}_{m \times 1}\\
\implies \vec{x}^{T} \cdot A &= x_{1} [A(1,:)] + x_{2}[A(2,:)]+\dots+[x_{m}A(m,:)]\\
\implies \vec{x}^{T} A &= x_{1} \begin{bmatrix}
a_{11} & a_{12} & \dots & a_{1 n}
\end{bmatrix}_{1 \times n} \\
&+ x_{2} \begin{bmatrix}
a_{21} & a_{22} & \dots & a_{2 n}
\end{bmatrix}_{1 \times n} \\
&+ x_{m} \begin{bmatrix}
a_{m 1} & a_{m 2} & \dots & a_{mn}
\end{bmatrix}_{1 \times n}
\end{align*}
$$

 <span style='float:right;'>$\blacklozenge$</span>
 ---
 
 **Remark.** Notice in the linear combination definition, we chunk the data into vector-sized pieces.
 <span style='float:right;'>$\blacklozenge$</span>
---

**Remark.** Notice that we define row-vector-matrix multiplication as the [[Linear Algebra/04 Vector Arithmetic/4.4 Transpose of a Vector\|transpose]] of a [[Linear Algebra/03 Vector Modeling/3.1 Column Vector\|3.1 Column Vector]]. It's defined as
$$
\begin{align}
[\vec{x}^{T}]_{1 \times m} [A]_{m \times n} &  & [\vec{x}] \in \mathbb{R}^{m \times 1}
\end{align}
$$
rather than
$$
\begin{align}
[\vec{x}] \cdot [A]  &  & [\vec{x}] \in \mathbb{R}^{1 \times m}
\end{align}
$$
because of something we are going study something in the future called quadratic form:
$$
\vec{y}^{T} k \vec{x}
$$
 <span style='float:right;'>$\blacklozenge$</span>

 
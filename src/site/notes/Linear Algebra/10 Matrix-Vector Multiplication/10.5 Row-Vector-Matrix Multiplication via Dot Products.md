---
{"date created":"Tuesday, May 14th 2024, 12:08:16 pm","date modified":"Wednesday, May 15th 2024, 2:44:51 pm","time spent":null,"tags":["Type/Definition","Topic/Linear_Algebra"],"links":"[[10 Matrix-Vector Multiplication]]","dg-publish":true,"permalink":"/linear-algebra/10-matrix-vector-multiplication/10-5-row-vector-matrix-multiplication-via-dot-products/","dgPassFrontmatter":true}
---

Types: *N/A*
Examples: [[Linear Algebra/10 Matrix-Vector Multiplication/10.5.1 Example of Row-Vector-Matrix Multiplication via Dot Products\|10.5.1 Example of Row-Vector-Matrix Multiplication via Dot Products]]
Constructions: *N/A*
Generalizations: *N/A*

Properties: [[Linear Algebra/10 Matrix-Vector Multiplication/10.7 Properties of Row-Vector-Matrix Multiplication\|10.7 Properties of Row-Vector-Matrix Multiplication]]
Sufficiencies: *N/A*
Questions: *N/A*

> [!definition|*] Row-Vector-Matrix Multiplication via Dot Products
> 
> Let matrix $A \in \mathbb{R}^{m \times n}$ and [[Linear Algebra/03 Vector Modeling/3.1 Column Vector\|3.1 Column Vector]] $\vec{x} \in \mathbb{R}^{m \times 1}$. We define the row-vector-matrix product $\vec{x}^{T} = \vec{b} \in \mathbb{R}^{1 \times n}$ via dot products using an entry-by-entry approach where the output is a [[Linear Algebra/03 Vector Modeling/3.4 Row Vector\|3.4 Row Vector]]. The $k$th entry of the product $\vec{b} = \vec{x}^{T} A$ can be calculated by an [[Linear Algebra/05 Inner Products and Vector Norms/5.1 Inner Product Between Vectors\|inner product]] between the $k$th column of $A$ and the vector $\vec{x}$:
> $$
> b_{k} = \text{entry}_{(1, k)} (\vec{x}^{T} A) = \vec{x} \cdot (A(:,k)) = \sum_{i=1}^{m} a_{ik}x_{i}
> $$
> for column index $k \in \{ 1,2,\dots,n \}$. When we calculate every entry of the output vector, we produce
> $$
> \vec{x}^{T} A = \begin{bmatrix}
> b_{1} & b_{2} & \dots & b_{n}
> \end{bmatrix}
> $$
> - In other words, we are taking the dot product of our column vector $\vec{x}$ and the $k$th column of $A$.

**Remark.** Recall that when working with matrices and vectors, the inner dimensions must agree.
$$
[\vec{b}]_{1 \times n} = [\vec{x}^{T}]_{1 \times m} \cdot [A]_{m \times n}
$$
- Number of columns of $\vec{x}^{T}$ matches the rows of $A$
- Output $\vec{b}$ is defined by the outer dimensions, $1 \times n$
 <span style='float:right;'>$\blacklozenge$</span>

---
**Remark.** Similar to [[Linear Algebra/10 Matrix-Vector Multiplication/10.4 Row-Vector-Matrix Multiplication via Linear Combinations\|10.4 Row-Vector-Matrix Multiplication via Linear Combinations]], we also partition the output vector into column partitions. Let's look at finding the entries of $\vec{b}$.
$$
\begin{align*}
\vec{b} &=  \vec{x}^{T} \cdot A\\
&= \vec{x}^{T}\cdot [\begin{array}{c|c|c}
A(:,1) & A(:,2) & \dots & A(:,n) 
\end{array}]\\
&= [\begin{array}{c|c|c}
b_{1} & b_{2} & \dots & b_{n}
\end{array}]\\
\\
\implies b_{1} &= \text{entry}_{(1,1)} (\vec{x}^{T} \cdot A)\\
&= \vec{x} \cdot A(:,1) \\
&= \begin{bmatrix}
x_{1} \\
x_{2} \\
\vdots \\
x_{m}
\end{bmatrix} \cdot \begin{bmatrix}
a_{11} \\
a_{21} \\
\vdots \\
a_{m 1}
\end{bmatrix} \\
&= x_{1} a_{11} + x_{2} a_{21} + \dots + x_{m} a_{m 1}\\
\\
\implies b_{2} &= \text{entry}_{(1, 2)} (\vec{x}^{T \cdot}A)\\
&= \vec{x} \cdot A(:,2)\\
&= \begin{bmatrix}
x_{1} \\
x_{2} \\
\vdots \\
x_{m}
\end{bmatrix} \cdot \begin{bmatrix}
a_{12} \\
a_{22} \\
\vdots \\
a_{m 2}
\end{bmatrix}\\
&= x_{1} a_{12} + x_{2} a_{22} + \dots x_{m} a_{m 2}\\
b_{2} &= \sum_{i=1}^{m} x_{i} a_{i 2}
\end{align*}
$$
 The last entry of output $\vec{b} = \vec{x}^{T} \cdot A$ is
 $$
\begin{align*}
\implies b_{k} &= \text{entry}_{(1,n)} (\vec{x}^{T} \cdot A)\\
&= \vec{x} \cdot A(:,n)\\
&= \begin{bmatrix}
x_{1} \\
x_{2} \\
\vdots \\
x_{m}
\end{bmatrix}_{1 \times m} \cdot \begin{bmatrix}
a_{1 k} \\
a_{2k} \\
\vdots \\
a_{mn}
\end{bmatrix}_{1 \times m}\\
&= x_{1}a_{1n} + x_{2}a_{2n} + \dots + x_{m}a_{mn}
\end{align*}
$$
Putting this all together, we have the entry-by-entry definition.
$$
\begin{align*}
[\begin{array}
{c|c|c} b_{1}  & b_{2}  & \dots & b_{n}
\end{array}]_{1 \times n} &= [\begin{array}
{c|c|c} x_{1} & x_{2}  &  \dots  & x_{m}
\end{array}]_{1 \times m} \left[ \begin{array}
{c|c|c} a_{11} & a_{12} &  & a_{1m} \\
a_{21} & a_{22} & \dots & a_{2m} \\
\vdots & \vdots &  & \vdots \\
a_{m 1} & a_{m 2} &  & a_{m n}
\end{array} \right]_{m \times n} \\
&= \left[ \begin{array}
{c|c|c} x_{1}a_{11}+x_{2}a_{21}+\dots+x_{m}a_{m 1} & \dots & x_{1}a_{1n} + x_{2}a_{2n}+\dots+x_{m}a_{mn}
\end{array} \right] 
\end{align*}
$$
 <span style='float:right;'>$\blacklozenge$</span>
 ---
 **Remark.** If we factor out the scalar multiples, we can produce the [[Linear Algebra/10 Matrix-Vector Multiplication/10.4 Row-Vector-Matrix Multiplication via Linear Combinations\|10.4 Row-Vector-Matrix Multiplication via Linear Combinations]] definition.
 $$
\begin{align*}
\implies [\vec{b}]_{1 \times m} &= x_{1} \begin{bmatrix}
a_{11} & a_{12} & \dots & a_{1n}
\end{bmatrix}\\
&+ x_{2} \begin{bmatrix}
a_{21} & a_{22} & \dots & a_{2n}
\end{bmatrix}\\
& \vdots\\
&+ x_{m} \begin{bmatrix}
a_{m1}  & a_{m 2} & \dots & a_{mn}
\end{bmatrix}
\end{align*}
$$
 Therefore, both methods produce the exact same output.
 - Dot product version focuses on producing scalar data
 - Linear combination version focuses on producing vector data
 <span style='float:right;'>$\blacklozenge$</span>